{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the packages and install packages\n",
    "#pip install pyabf\n",
    "import pyabf\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87933877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#abf files were converted to the .mat files after NanoporeAPP processing, and events, pkmax, dwell time and area information were extracted using NanoporeAPP\n",
    "# Load the .mat file\n",
    "mat_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\event_test_length.mat')\n",
    "peak_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\pkmax_test_length.mat')\n",
    "width_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\width_test_length.mat')\n",
    "area_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\area_test_length.mat')\n",
    "\n",
    "# Access the data in the .mat file\n",
    "env_time = ((mat_file[\"Event\"][0][0][0][0][2]).T)[0]\n",
    "env_current = ((mat_file[\"Event\"][0][0][0][0][1]).T)[0]\n",
    "\n",
    "# Create a plot\n",
    "plt.scatter(env_time,env_current)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Current')\n",
    "plt.title('Current vs Time')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1146a4a",
   "metadata": {},
   "source": [
    "## nanopore descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df88ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the current distribution within dwell time\n",
    "ratio_list = []\n",
    "#get the event data, time and current\n",
    "for i in range(len(mat_file[\"Event\"][0])):\n",
    "    env_time = ((mat_file[\"Event\"][0][i][0][0][2]).T)[0]\n",
    "    env_current = ((mat_file[\"Event\"][0][i][0][0][1]).T)[0]\n",
    "\n",
    "# Define the range of dwell time values to select\n",
    "    x_min = ((mat_file[\"Event\"][0][i][0][0][3]).T)[0][0]\n",
    "    x_max = ((mat_file[\"Event\"][0][i][0][0][3]).T)[0][-1]\n",
    "\n",
    "# Use boolean indexing to select the data points that fall within the range of dwell time values\n",
    "    dwell_current = []\n",
    "    dwell_time = ((mat_file[\"Event\"][0][i][0][0][3]).T)[0]\n",
    "    for a in range(len(env_time)):\n",
    "        if env_time[a] >= x_min and env_time[a] <= x_max:\n",
    "            dwell_current.append(env_current[a])\n",
    "\n",
    "# Divide the dwell time and dwell current axes into sub-parts\n",
    "    x_bins = np.linspace(x_min, x_max, 5 + 1)\n",
    "    y_bins = np.linspace(0.015, float(peak_file[\"PkMax\"][i]+0.01), 10 + 1)\n",
    "\n",
    "# Calculate the number of points within each sub-part\n",
    "    counts,time_edges,current_edges = np.histogram2d(dwell_time, dwell_current, bins=(x_bins, y_bins))\n",
    "\n",
    "# Calculate the ratio of points within each sub-part to the total number of points\n",
    "    ratios = counts / np.sum(counts)\n",
    "    ratios = ratios.T\n",
    "    ratio_list.append(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ratio_list[0], cmap='viridis', origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ebefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the labels and put the labels together with the event indexes\n",
    "#index_lists = {\n",
    "   # 'F_0': [5, 6, 12, 15, 17, 24, 26, 27, 36, 39, 43, 44, 45, 48, 51, 54, 59, 64, 68, 70, 74, 75, 76, 79, 3997, 82, 87, 3989, 91, 92, 99, 110, 118, 119, 124, 126, 140, 143, 144, 3988, 3984, 149, 166, 170, 174, 3982, 180, 182, 185, 191, 211, 221, 224, 236, 237, 238, 239, 243, 245, 254, 263, 264, 265, 268, 271, 277, 284, 289, 291, 298, 299, 300, 303, 305, 306, 309, 311, 3979, 317, 318, 323, 341, 343, 346, 349, 356, 358, 3977, 370, 3978, 380, 381, 383, 396, 398, 399, 400, 402, 404, 406, 408, 412, 3975, 419, 420, 426, 428, 431, 3973, 434, 438, 3972, 449, 458, 464, 467, 474, 475, 476, 477, 487, 491, 498, 499, 501, 506, 510, 518, 3965, 527, 534, 535, 537, 545, 546, 552, 553, 555, 559, 565, 575, 577, 583, 584, 585, 587, 591, 592, 599, 606, 607, 610, 615, 617, 623, 633, 635, 638, 639, 644, 646, 647, 648, 653, 655, 657, 662, 665, 675, 683, 686, 694, 702, 709, 710, 711, 716, 729, 3964, 736, 740, 741, 744, 745, 748, 753, 757, 759, 765, 768, 769, 772, 775, 785, 790, 791, 792, 3962, 803, 804, 805, 821, 3956, 833, 837, 845, 846, 847, 849, 851, 860, 862, 869, 877, 880, 882, 886, 888, 891, 893, 894, 903, 904, 905, 906, 908, 909, 916, 928, 931, 932, 935, 939, 942, 943, 955, 956, 962, 971, 973, 976, 986, 996, 999, 1000, 1001, 1005, 1010, 1012, 1015, 1020, 1027, 1029, 1030, 1032, 1033, 1034, 1036, 1038, 1042, 1044, 1046, 1048, 1062, 1064, 1065, 1079, 1080, 1089, 1090, 1093, 1098, 1104, 1109, 1112, 1130, 1139, 1140, 1146, 1147, 1150, 1151, 1159, 1164, 1172, 1175, 1178, 1180, 1182, 1187, 1192, 1198, 1203, 1208, 1218, 1227, 1228, 1231, 1233, 1236, 1243, 1244, 1245, 1252, 1262, 1268, 1269, 1273, 1283, 1290, 1297, 1300, 1302, 1314, 1315, 1317, 1326, 1334, 1343, 1345, 1348, 1358, 1361, 1368, 1370, 1372, 1388, 1390, 1391, 1394, 1396, 1399, 1404, 1406, 1408, 1412, 1414, 1419, 1420, 1430, 1432, 1434, 1435, 1440, 1444, 1445, 1448, 1460, 1465, 1466, 1474, 1482, 1484, 1485, 1486, 1488, 1489, 1492, 1500, 1507, 1512, 1528, 5565, 5564, 5560, 5554, 5547, 5544, 5542, 5538, 5537, 5534, 5530, 5529, 5521, 5504, 5503, 5494, 5483, 5482, 5479, 5477, 5469, 5465, 5464, 5459, 5451, 5449, 5438, 5427, 5426, 5424, 5418, 5394, 5392, 5391, 5387, 5385, 5376, 5372, 5354, 5352, 5351, 5349, 5347, 5344],\n",
    "   # 'F_10110': [14, 29, 33, 53, 55, 61, 66, 83, 88, 104, 105, 114, 115, 117, 122, 130, 135, 141, 167, 168, 177, 178, 197, 228, 233, 234, 235, 240, 241, 242, 255, 260, 275, 278, 294, 312, 313, 333, 338, 350, 368, 374, 379, 388, 389, 407, 417, 423, 424, 436, 440, 442, 447, 454, 465, 468, 470, 478, 493, 495, 497, 500, 505, 512, 513, 523, 525, 529, 533, 536, 550, 557, 561, 563, 564, 568, 576, 593, 596, 597, 612, 620, 628, 636, 637, 641, 656, 663, 664, 3998, 685, 693, 703, 713, 720, 738, 743, 747, 754, 755, 773, 783, 798, 806, 807, 808, 813, 820, 826, 827, 834, 842, 870, 884, 887, 889, 890, 901, 902, 907, 917, 918, 921, 922, 941, 945, 951, 953, 958, 963, 969, 972, 984, 992, 1006, 1018, 1026, 1037, 1056, 1063, 1066, 1076, 1083, 1084, 1086, 1088, 1110, 1111, 1116, 1119, 1120, 1123, 1124, 1128, 1129, 1152, 1155, 1165, 1169, 1179, 1183, 1184, 1189, 1190, 1197, 1217, 1223, 1225, 1230, 1232, 1235, 1237, 1248, 1257, 1266, 1278, 1280, 1284, 1285, 1287, 1295, 1298, 1308, 1311, 1321, 1324, 1328, 1331, 1346, 1355, 1359, 1364, 1367, 1369, 1371, 1373, 1374, 1375, 1383, 1386, 1398, 1400, 1401, 1410, 1411, 1418, 1425, 1431, 1442, 1450, 1451, 1456, 1463, 1467, 1468, 1472, 1475, 1477, 1504, 1509, 1513, 1519, 1526, 1527, 1540, 1541, 1560, 1574, 1575, 1576, 1582, 1599, 1603, 1604, 1606, 1631, 1635, 1639, 1642, 1645, 1648, 1653, 1657, 1659, 1663, 1667, 1675, 1693, 1696, 1699, 1708, 1716, 1720, 1722, 1735, 1736, 1746, 1747, 1753, 1772, 1779, 1789, 1790, 1799, 1809, 1816, 1827, 1831, 1836, 1837, 1840, 1841, 1849, 1850, 1855, 1864, 1866, 1871, 1873, 1882, 1885, 1890, 1910, 1912, 1915, 1917, 1919, 1926, 1929, 1933, 1936, 1941, 1942, 1943, 1944, 1958, 1963, 1965, 1966, 1975, 1982, 1986, 1995, 5573, 5571, 5570, 5569, 5568, 5567, 5568, 5569, 5568, 5567, 5558, 5552, 5551, 5539, 5524, 5523, 5519, 5517, 5515, 5509, 5508, 5502, 5498, 5496, 5495, 5490, 5487, 5478, 5472, 5467, 5461, 5456, 5455, 5453, 5450, 5442, 5439, 5437, 5436, 5434, 5432, 5430, 5423, 5421, 5415, 5413, 5410, 5400, 5396, 5388, 5384, 5382, 5377, 5367, 5364, 5362, 5359, 5353, 5350, 5345, 5341, 5340, 5338, 5329, 5319, 5316, 5304, 5299, 5298, 5290, 5287, 5279, 5273, 5268, 5262, 5259, 5251, 5247, 5244, 5232, 5206, 5203, 5201, 5200, 5298, 5192, 5189, 5180, 5179, 5176, 5175, 5173, 5172, 5169, 5167, 5150, 5149, 5147, 5142, 5129, 5128, 5126, 5121, 5116],\n",
    "   # 'F_110': [38, 42, 57, 60, 69, 132, 139, 159, 160, 186, 194, 327, 405, 446, 483, 488, 504, 520, 522, 547, 578, 600, 613, 616, 697, 784, 802, 843, 848, 850, 861, 881, 883, 944, 975, 991, 994, 998, 1014, 1049, 1061, 1078, 1102, 1137, 1144, 1149, 1170, 1211, 1229, 1246, 1258, 1271, 1292, 1310, 1319, 1405, 1446, 1469, 1496, 1516, 1532, 1543, 1567, 1572, 1586, 1640, 1691, 1718, 1730, 1733, 1766, 1773, 1787, 1811, 1820, 1838, 1853, 1867, 1908, 1934, 1974, 2109, 2125, 2136, 2148, 2196, 2252, 2263, 2275, 2317, 2322, 2356, 2357, 2373, 2412, 2423, 2480, 2498, 2548, 2576, 2581, 2626, 2683, 2732, 2743, 2765, 2802, 2805, 2818, 2821, 2850, 2851, 2867, 2890, 2895, 2902, 2912, 2939, 2963, 2968, 2985, 3021, 3032, 3036, 3060, 3134, 3150, 3170, 3175, 3204, 3264, 3276, 3292, 3297, 3331, 3373, 3411, 3461, 3477, 3494, 3498, 3520, 3536, 3559, 3570, 3574, 3585, 3604, 3610, 3626, 3691, 3779, 3786, 3799, 3835, 3841, 3843, 3867, 3874, 3882, 3888, 3939, 4004, 4013, 4028, 4087, 4090, 4132, 4172, 4187, 4195, 4207, 4239, 4240, 4247, 4269, 4280, 4284, 4337, 4406, 4499, 4526, 4541, 4579, 4606, 4635, 4659, 4661, 4671, 4713, 4741, 4767, 4834, 4921, 4926, 5011, 5022, 5039, 5066, 5078, 5098, 5131, 5156, 5161, 5184, 5208, 5241, 5274, 5297, 5323, 5355, 5399, 5403, 5460, 5470, 5473, 5486, 5501, 5518, 5536, 5556, 5559, 5562, 5563, 283],\n",
    "   # 'F_10100': [129, 181, 195, 199, 209, 280, 364, 481, 619, 630, 645, 814, 1009, 1067, 1077, 1094, 1136, 1177, 1247, 1264, 1288, 1387, 1479, 1481, 1491, 1578, 1632, 1677, 1732, 1792, 1937, 2042, 2155, 2192, 2195, 2281, 2342, 2397, 2432, 2490, 2604, 2612, 2615, 2659, 2706, 2746, 2982, 3080, 3089, 3097, 3109, 3131, 3182, 3239, 3324, 3407, 3478, 3490, 3630, 3698, 3720, 3722, 3735, 4297, 4302, 4315, 4448, 4460, 4532, 4576, 4700, 4711, 4745, 4824, 4888, 4895, 4975, 4992, 5046, 5062, 5084, 5117, 5139, 5171, 5178, 5188, 5339, 5348, 5361, 5368, 5406, 5466, 5546, 5550, 5566, 5577, 5579, 5580, 5516, 1299],\n",
    "   # 'F_10010': [282, 451, 456, 466, 486, 737, 778, 915, 924, 980, 1069, 1376, 1499, 1522, 1554, 1600, 1685, 2034, 2104, 2167, 2392, 2393, 2455, 2523, 2569, 2616, 2630, 2716, 2831, 2928, 2941, 3086, 3201, 3266, 3320, 3406, 3569, 3600, 3650, 3753, 3771, 3881, 3950, 4222, 4392, 4446, 4520, 4749, 4766, 4854, 4924, 4925, 4952, 5133, 5185, 5220, 5229, 5317, 5340, 5452, 5493, 5513],\n",
    "   # 'T_0': [0, 3, 4, 9, 10, 11, 16, 18, 20, 21, 22, 25, 30, 35, 40, 41, 46, 52, 58, 71, 72, 77, 78, 81, 84, 89, 93, 95, 97, 101, 102, 103, 108, 109, 111, 113, 116, 121, 123, 125, 127, 128, 131, 133, 134, 136, 137, 152, 153, 155, 158, 161, 162, 163, 164, 165, 171, 172, 175, 176, 183, 184, 187, 190, 193, 196, 201, 203, 204, 205, 207, 208, 210, 212, 213, 214, 216, 218, 219, 220, 225, 226, 227, 229, 231, 244, 247, 248, 249, 252, 253, 258, 261, 262, 267, 269, 270, 273, 274, 276, 279, 281, 287, 288, 293, 296, 297, 304, 310, 315, 320, 322, 325, 326, 328, 330, 331, 332, 335, 337, 339, 340, 344, 345, 348, 351, 352, 357, 360, 376, 378, 385, 387, 390, 393, 395, 397, 401, 410, 413, 414, 415, 416, 425, 427, 429, 435, 443, 444, 448, 450, 452, 455, 459, 460, 462, 463, 490, 492, 494, 502, 503, 519, 521, 524, 528, 530, 531, 538, 539, 540, 541, 542, 543, 551, 556, 581, 588, 594, 603, 605, 609, 614, 621, 634, 649, 651, 658, 661, 669, 678, 679, 680, 681, 684, 690, 696, 699, 704, 705, 708, 714, 717, 719, 723, 725, 727, 730, 732, 735, 739, 742, 749, 751, 760, 763, 764, 766, 776, 780, 782, 786, 787, 788, 789, 793, 799, 801, 811, 812, 818, 819, 823, 824, 825, 828, 829, 836, 838, 840, 841, 844, 853, 854, 855, 857, 863, 866, 868, 871, 873, 874, 875, 876, 878, 892, 896, 900, 910, 911, 912, 920, 923, 925, 926, 929, 933, 934, 936, 938, 940, 947, 948, 949, 950, 952, 957, 959, 960, 964, 965, 968, 970, 977, 987, 989, 993, 997, 1004, 1021, 1022, 1023, 1035, 1041, 1047, 1050, 1051, 1052, 1055, 1058, 1060, 1071, 1072, 1075, 1085, 1097, 1101, 1106, 1108, 1117, 1118, 1121, 1126, 1134, 1143, 1153, 1156, 1158, 1160, 1162, 1163, 1166, 1173, 1174, 1191, 1194, 1195, 1196, 1200, 1205, 1206, 1207, 1209, 1212, 1216, 1220, 1221, 1222, 1224, 1238, 1241, 1242, 1253, 1254, 1256, 1259, 1265, 1267, 1270, 1272, 1274, 1275, 1277, 1279, 1281, 1286, 1294, 1303, 1304, 1306, 1318, 1320, 1323, 1325, 1327, 1333, 1335, 1337, 1342, 1344, 1347, 1352, 1353, 1354, 1357, 1363, 1377, 1378, 1392, 1393, 1403, 1413, 1415, 1416, 1417, 1421, 1423, 1426, 1427, 1429, 1437, 1438, 1441, 1447, 1449, 1453, 1454, 1455, 1457, 1470, 1471, 1476, 1478, 1483, 1490, 1494, 1495, 1498, 1501, 1502, 1503, 1505, 1518, 1523, 1531, 5575, 5561, 5555, 5553, 5543, 5541, 5540, 5533, 5531, 5514, 5510, 5507, 5506, 5500, 5499, 5492, 5489, 5488, 5485, 5484, 5481, 5476, 5463, 5458, 5445, 5441, 5435, 5429, 5420, 5414, 5411, 5386, 5381, 5380, 5379, 5378, 5374, 5371, 5365, 5358, 5356, 5342, 5314, 5313, 5292, 5278, 5277, 5275, 5267, 5266, 5250, 5246, 5240, 5239, 5238, 5127],\n",
    "   # 'T_10110': [1, 2, 7, 8, 13, 19, 23, 28, 31, 32, 34, 37, 47, 49, 50, 56, 62, 63, 65, 67, 73, 94, 100, 107, 112, 120, 138, 142, 145, 148, 150, 151, 154, 156, 157, 173, 189, 192, 198, 200, 202, 206, 217, 222, 223, 232, 250, 256, 257, 266, 285, 286, 290, 295, 302, 307, 308, 319, 321, 324, 329, 334, 336, 342, 347, 353, 354, 355, 359, 361, 362, 365, 366, 367, 369, 373, 375, 377, 382, 384, 386, 392, 394, 403, 409, 411, 421, 422, 430, 437, 439, 441, 453, 457, 461, 471, 472, 479, 480, 482, 485, 489, 496, 507, 511, 517, 532, 544, 548, 549, 554, 558, 560, 566, 567, 569, 570, 571, 572, 579, 582, 586, 589, 590, 595, 598, 601, 608, 611, 618, 624, 625, 626, 627, 632, 642, 643, 650, 652, 654, 659, 660, 667, 668, 671, 672, 673, 674, 676, 682, 687, 689, 691, 695, 698, 700, 706, 707, 715, 718, 722, 724, 728, 731, 733, 746, 750, 752, 756, 758, 761, 762, 770, 771, 774, 779, 781, 795, 796, 797, 800, 809, 810, 815, 817, 822, 832, 835, 839, 852, 856, 858, 859, 865, 867, 879, 885, 895, 899, 913, 919, 927, 930, 937, 946, 954, 961, 966, 967, 974, 978, 979, 981, 982, 983, 985, 988, 990, 995, 1003, 1008, 1011, 1013, 1016, 1017, 1019, 1024, 1025, 1028, 1031, 1040, 1045, 1053, 1054, 1057, 1059, 1068, 1070, 1073, 1081, 1082, 1091, 1092, 1095, 1096, 1099, 1100, 1103, 1105, 1107, 1113, 1114, 1115, 1125, 1127, 1132, 1133, 1135, 1141, 1145, 1148, 1154, 1157, 1161, 1167, 1168, 1171, 1176, 1181, 1186, 1188, 1193, 1199, 1201, 1202, 1204, 1210, 1213, 1214, 1226, 1234, 1239, 1240, 1250, 1255, 1260, 1261, 1276, 1282, 1289, 1293, 1296, 1301, 1305, 1307, 1309, 1312, 1313, 1316, 1322, 1329, 1330, 1332, 1336, 1338, 1339, 1340, 1341, 1349, 1350, 1351, 1360, 1362, 1365, 1366, 1379, 1380, 1381, 1382, 1384, 1385, 1389, 1395, 1397, 1402, 1407, 1409, 1424, 1433, 1436, 1443, 1452, 1461, 1462, 1473, 1480, 1487, 1493, 1497, 1506, 1510, 1511, 1514, 1515, 1517, 1520, 1521, 1525, 1529, 1530, 1552, 5584, 5583, 5582, 5581, 5578, 5576, 5572, 5557, 5549, 5548, 5545, 5535, 5526, 5525, 5522, 5520, 5512, 5511, 5497, 5491, 5480, 5475, 5474, 5468, 5462, 5457, 5454, 5448, 5447, 5446, 5443, 5440, 5433, 5431, 5428, 5425, 5422, 5419, 5417, 5416, 5412, 5408, 5405, 5404, 5402, 5401, 5398, 5397, 5395, 5393, 5390, 5389, 5383, 5375, 5373, 5370, 5369, 5366, 5363, 5360, 5357, 5346, 5343, 5337, 5335, 5333, 5332, 5331, 5330, 5327, 5326, 5325, 5324, 5318, 5312, 5309, 5308, 5307, 5306, 5305, 5302, 5301, 5296, 5295, 5294, 5293, 5291, 5289, 5285, 5283, 5280, 5276, 5261, 5260, 5254, 5253, 5249, 5248, 5236, 5233, 5225, 5224, 5216, 5213, 5204, 5202, 5197, 5196, 5195, 5194, 5191, 5190, 5181, 5164, 5162, 5158, 5153, 5151, 5148, 5136, 5130],\n",
    "   # 'T_110': [85, 86, 96, 98, 106, 169, 188, 215, 230, 246, 251, 272, 301, 316, 371, 391, 469, 473, 484, 514, 573, 602, 604, 622, 640, 688, 701, 712, 721, 726, 767, 816, 864, 872, 897, 898, 1007, 1039, 1074, 1087, 1131, 1185, 1215, 1219, 1249, 1263, 1291, 1356, 1422, 1508, 1524, 1555, 1610, 1701, 1726, 1800, 1895, 1950, 1996, 2082, 2199, 2200, 2256, 2331, 2361, 2439, 2466, 2468, 2500, 2520, 2521, 2667, 2695, 2771, 2792, 2920, 2938, 2962, 3076, 3096, 3149, 3296, 3314, 3352, 3379, 3432, 3488, 3580, 3633, 3793, 3832, 3847, 3873, 4155, 4309, 4402, 4411, 4445, 4491, 4500, 4511, 4544, 4614, 4716, 4723, 4731, 4773, 4793, 4845, 4996, 5045, 5073, 5095, 5118, 5243, 5407, 5471, 5527, 5528, 5532, 5574],\n",
    "   # 'T_10100': [259, 292, 508, 509, 515, 516, 562, 574, 580, 692, 777, 914, 1043, 1138, 1142, 1464, 1533, 1668, 1723, 1788, 1803, 1826, 1848, 2044, 2060, 2071, 2346, 2428, 2449, 2694, 2909, 3040, 3216, 3254, 3268, 3317, 3339, 3400, 3416, 3456, 3506, 3519, 3551, 3672, 3676, 3700, 3740, 3794, 3840, 3865, 3908, 3943, 3947, 4119, 4215, 4268, 4296, 4420, 4461, 4485, 4699, 4714, 4904, 4934, 4948, 4948, 5027, 5137, 5140, 5144, 5212, 5505, 5585, 432],\n",
    "   # 'T_10010': [629, 631, 666, 670, 831, 1002, 1122, 1251, 1428, 1439, 1458, 1459, 1833, 1900, 2305, 2429, 2541, 2607, 2669, 3017, 3062, 3106, 3179, 3274, 3302, 3389, 3443, 3493, 3546, 3631, 3697, 3775, 3892, 3969, 3986, 3994, 4014, 4055, 4094, 4126, 4139, 4171, 4274, 4398, 4462, 4531, 4582, 4655, 4708, 4726, 4782, 4804, 4830, 4844, 4869, 5006, 5170, 5177, 5221, 5260, 5409, 5444]\n",
    "#}\n",
    "\n",
    "\n",
    "# Create a new list for extracted graphs\n",
    "extracted_graphs = []\n",
    "extracted_pkmax = []\n",
    "extracted_width = []\n",
    "extracted_area = []\n",
    "\n",
    "# Iterate over the lists of indexes\n",
    "for indexes in index_lists.values():\n",
    "    # Retrieve the graphs based on the indexes\n",
    "    graphs = [ratio_list[index] for index in indexes]\n",
    "    # Add the extracted graphs to the new list\n",
    "    extracted_graphs.extend(graphs)\n",
    "    # Add the extracted features to the new list\n",
    "    pmax = (float(peak_file[\"PkMax\"][index]) for index in indexes)\n",
    "    wth = (float(width_file[\"Width\"][index]) for index in indexes)\n",
    "    area = (float(area_file[\"Area\"][index]) for index in indexes)\n",
    "    # Add the feature to the new list\n",
    "    extracted_pkmax.extend(pmax)\n",
    "    extracted_width.extend(wth)\n",
    "    extracted_area.extend(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c970c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels for the events\n",
    "nlength_labels = [0] * 406 + [10110] * 407 + [110] * 225 + [10100] * 100 + [10010] * 62 + [0] * 471 + [10110] * 472 + [110] * 121 + [10100] * 74 + [10010] * 62\n",
    "length_labels = [0] * 406 + [10110] * 407 + [110] * 225 + [10100] * 100 + [10010] * 62 + [10] * 471 + [110110] * 472 + [1110] * 121 + [110100] * 74 + [110010] * 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all the time, pkmax and charge information together\n",
    "pkmax_list = []\n",
    "charge_list = []\n",
    "dwell_time_list = []\n",
    "for i in range(len(peak_file[\"PkMax\"])):\n",
    "    pkmax_list.append(float(peak_file[\"PkMax\"][i]))\n",
    "    charge_list.append(float(area_file[\"Area\"][i]))\n",
    "    dwell_time_list.append(float(width_file[\"Width\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an empty list for combining all the data lists\n",
    "combined_pkmax_list = []\n",
    "combined_charge_list = []\n",
    "combined_dwell_time_list = []\n",
    "#combine the ratio lists together\n",
    "combined_pkmax_list.extend(pkmax_list)\n",
    "print(len(combined_pkmax_list))\n",
    "combined_charge_list.extend(charge_list)\n",
    "print(len(combined_charge_list))\n",
    "combined_dwell_time_list.extend(dwell_time_list)\n",
    "print(len(combined_dwell_time_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc043be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the event indexes into the dataframe,in this case, event indexes are added after 50 pixel current density graph\n",
    "flatten_ratios = []\n",
    "for ratios in ratio_list:\n",
    "    flatten_ratios.append(ratios.flatten())\n",
    "faltten_df = pd.DataFrame(flatten_ratios)\n",
    "faltten_df[50] = combined_pkmax_list\n",
    "faltten_df[51] = combined_charge_list\n",
    "faltten_df[52] = combined_dwell_time_list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b234983e",
   "metadata": {},
   "source": [
    "#append more information into the ratio list\n",
    "#this dataframe is using length as a feature, not the difference between labels\n",
    "flatten_ratios = []\n",
    "for ratios in extracted_graphs:\n",
    "    flatten_ratios.append(ratios.flatten())\n",
    "faltten_df = pd.DataFrame(flatten_ratios)\n",
    "faltten_df[1600] = extracted_pkmax\n",
    "faltten_df[1601] = extracted_area\n",
    "faltten_df[1602] = extracted_width\n",
    "# add the numbers 200 to df\n",
    "length_list = [5] * 1200 + [10] * 1200\n",
    "faltten_df[1603] = length_list\n",
    "faltten_df[1604] = nlength_labels\n",
    "faltten_df[1605] = length_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc574f",
   "metadata": {},
   "source": [
    "## supervised learning codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the packages and install packages\n",
    "#pip install pyabf\n",
    "import pyabf\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the files for training,in this case, 50 pixel number file is used\n",
    "filename = 'combined_length_50px_v1.pkl'\n",
    "file_path = 'C:\\\\python_intro\\\\final_project\\\\'\n",
    "with open(file_path + filename, 'rb') as file:\n",
    "    combined_ratios_all = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437182c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns except the last two as inputs\n",
    "combined_ratios = combined_ratios_all.iloc[:, :-3]\n",
    "# Select the last two columns as labels\n",
    "labels = combined_ratios_all.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making labels as ground truth\n",
    "labels_column = labels[55].tolist()\n",
    "#binary_labels = [0 if label == 0 else 1 for label in labels_column]\n",
    "ground_truth = labels_column\n",
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the event index columns\n",
    "cols_to_normalize = combined_ratios.columns[-3:]\n",
    "scaler = MinMaxScaler()\n",
    "combined_ratios[cols_to_normalize] = scaler.fit_transform(combined_ratios[cols_to_normalize])\n",
    "# Print the normalized DataFrame\n",
    "combined_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ground_truth to a numpy array for easier indexing\n",
    "from sklearn.model_selection import train_test_split\n",
    "ground_truth = np.array(ground_truth)\n",
    "# Initialize empty lists to store training and testing datasets and labels\n",
    "training_data = []\n",
    "testing_data = []\n",
    "training_labels = []\n",
    "testing_labels = []\n",
    "\n",
    "# Get unique labels from the ground_truth list\n",
    "unique_labels = np.unique(ground_truth)\n",
    "\n",
    "# Iterate over each unique label\n",
    "for label in unique_labels:\n",
    "    # Find the indices where the label matches\n",
    "    label_indices = np.where(ground_truth == label)[0]\n",
    "\n",
    "    # Check if there is more than one sample for the label\n",
    "    if len(label_indices) > 1:\n",
    "        # Split the label indices into training and testing sets with an 80/20 ratio\n",
    "        train_indices, test_indices = train_test_split(label_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Append the corresponding rows from combined_ratios to the training and testing datasets\n",
    "        training_data.append(combined_ratios.iloc[train_indices])\n",
    "        testing_data.append(combined_ratios.iloc[test_indices])\n",
    "\n",
    "        # Append the corresponding labels to the training and testing labels\n",
    "        training_labels.extend(ground_truth[train_indices])\n",
    "        testing_labels.extend(ground_truth[test_indices])\n",
    "\n",
    "# Concatenate all training datasets into a single DataFrame\n",
    "training_data = pd.concat(training_data)\n",
    "\n",
    "# Concatenate all testing datasets into a single DataFrame\n",
    "testing_data = pd.concat(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training and testing datasets\n",
    "training_flatten = training_data.values\n",
    "testing_flatten = testing_data.values\n",
    "training_graph_data = training_data.iloc[:, :50].values\n",
    "testing_graph_data = testing_data.iloc[:, :50].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3206e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert ground truth to encoded_labels for NN\n",
    "unique_training_classes = np.unique(training_labels)# Find the unique classes\n",
    "unique_testing_classes = np.unique(testing_labels)\n",
    "\n",
    "num_training_classes = len(unique_training_classes)\n",
    "num_testing_classes = len(unique_testing_classes)\n",
    "\n",
    "encoded_training_labels = np.zeros((len(training_labels), num_training_classes))  # Initialize an array for one-hot encoding\n",
    "encoded_testing_labels = np.zeros((len(testing_labels), num_testing_classes))\n",
    "\n",
    "for i, label in enumerate(training_labels):\n",
    "    class_training_index = np.where(unique_training_classes == label)[0][0]  # Find the index of the class\n",
    "    encoded_training_labels[i, class_training_index] = 1  # Set the corresponding element to 1\n",
    "    \n",
    "for i, label in enumerate(testing_labels):\n",
    "    class_testing_index = np.where(unique_testing_classes == label)[0][0]  # Find the index of the class\n",
    "    encoded_testing_labels[i, class_testing_index] = 1  # Set the corresponding element to 1\n",
    "\n",
    "print(encoded_testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and testing datasets for all descriptor datasets\n",
    "X_train_NN = np.array(training_flatten)\n",
    "X_test_NN = np.array(testing_flatten)\n",
    "y_train_NN = encoded_training_labels\n",
    "y_test_NN = encoded_testing_labels\n",
    "X_train = training_flatten\n",
    "X_test = testing_flatten\n",
    "y_train = training_labels\n",
    "y_test = testing_labels\n",
    "X_train_en = training_flatten\n",
    "X_test_en = testing_flatten\n",
    "y_train_en = encoded_training_labels\n",
    "y_test_en = encoded_testing_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabdb2f7",
   "metadata": {},
   "source": [
    "## training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a88966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define the hyperparameters to be searched\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 200, 500, 1000, 1500, 2000, 5000, 7500, 10000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create the Grid Search object\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the Grid Search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and accuracy score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best accuracy: \", grid_search.best_score_)\n",
    "\n",
    "# Train the Random Forest classifier using the best hyperparameters\n",
    "rf_best = RandomForestClassifier(**grid_search.best_params_)\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the test data\n",
    "y_pred = rf_best.predict(X_test)\n",
    "\n",
    "# Compute accuracy, F1 score, and ROC-AUC score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the scores\n",
    "print(\"Test accuracy: \", accuracy)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Import the model and the grid search for finding the best hyperparameters\n",
    "svm = SVC()\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 250, 500, 1000, 2500, 5000, 7500, 10000],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10, 100]\n",
    "}\n",
    "clf = GridSearchCV(svm, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best combination of hyperparameters\n",
    "best_params = clf.best_params_\n",
    "best_score = clf.best_score_\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "# Use the best hyperparameters to predict the testing dataset\n",
    "best_estimator = clf.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Print the scores for prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Calculate the weighted F1 score\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "gnb = GaussianNB()\n",
    "param_grid = {\n",
    "    'priors': [None, [0.2, 0.8], [0.5, 0.5]],\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3],\n",
    "}\n",
    "clf = GridSearchCV(gnb, param_grid, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "best_params = clf.best_params_\n",
    "best_score = clf.best_score_\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "best_estimator = clf.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92110320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9], \n",
    "    'weights': ['uniform', 'distance'], \n",
    "    'algorithm': [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    'leaf_size': [10, 20, 30, 40]\n",
    "}\n",
    "clf = GridSearchCV(knn, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "best_params = clf.best_params_\n",
    "best_score = clf.best_score_\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "best_estimator = clf.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9219a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    #keras.layers.Dense(256, activation='relu'),\n",
    "    #keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    #keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "    #keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "num_runs = 10\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train_NN, y_train_NN, epochs=100, batch_size=32, validation_data=(X_test_NN, y_test_NN), callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the best model on the test data\n",
    "    loss, accuracy = model.evaluate(X_test_NN, y_test_NN)\n",
    "    losses.append(loss)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the average loss and accuracy\n",
    "average_loss = sum(losses) / num_runs\n",
    "average_accuracy = sum(accuracies) / num_runs\n",
    "\n",
    "# Print the average loss and accuracy\n",
    "print(\"Average loss:\", average_loss)\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred_prob = model.predict(X_test_NN)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "test_labels = np.argmax(y_test_NN, axis=1)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(test_labels, y_pred, average='weighted')\n",
    "\n",
    "# Print the best epoch and F1 score\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3da080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradientboost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 150, 300],\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'learning_rate': [1, 0.1, 0.01, 0.001]\n",
    "} \n",
    "\n",
    "clf = GridSearchCV(gbm, param_grid, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "best_params = clf.best_params_\n",
    "best_score = clf.best_score_\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "best_estimator = clf.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f657dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 150, 300],\n",
    "    'learning_rate': [1, 0.1, 0.01, 0.001],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(ada, param_grid, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "best_params = clf.best_params_\n",
    "best_score = clf.best_score_\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "best_estimator = clf.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492fd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_clf = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [1, 0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'n_estimators': [10, 50, 100, 150, 300],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Perform a grid search over the hyperparameters\n",
    "clf = GridSearchCV(xgb_clf, param_grid, cv=5)\n",
    "clf.fit(X_train_en, y_train_en)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "best_params = clf.best_params_\n",
    "best_score = clf.best_score_\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "# Use the best estimator to make predictions on the test set and calculate accuracy and F1 score\n",
    "best_estimator = clf.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test_en)\n",
    "accuracy = accuracy_score(y_test_en, y_pred)\n",
    "f1 = f1_score(y_test_en, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aeca49",
   "metadata": {},
   "source": [
    "## error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb06544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best models and see the labels they predicted using testing dataset (10 classes)\n",
    "#SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "svc_all = []\n",
    "nn_all = []\n",
    "for i in range(5):\n",
    "    svc_classifier = SVC(C = 100, gamma = \"scale\", kernel = 'rbf',probability=True, random_state=42)\n",
    "    svc_classifier.fit(X_train, y_train)\n",
    "    svc_proba = svc_classifier.predict_proba(X_test)\n",
    "    svc_all.append(svc_proba)\n",
    "\n",
    "    #NN\n",
    "    #define the model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "        #keras.layers.Dense(256, activation='relu'),\n",
    "        #keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        #keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(5, activation='softmax')\n",
    "        #keras.layers.Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Add layers to the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train_NN, y_train_NN, validation_data=(X_test_NN, y_test_NN), epochs=100, callbacks=[early_stopping])\n",
    "    # Use the model obtained at the end of training\n",
    "    nn_predicted_proba = model.predict(X_test_NN)\n",
    "    nn_all.append(nn_predicted_proba)\n",
    "\n",
    "#get the average values of 5 times of training\n",
    "nn_average = np.mean(nn_all, axis=0)\n",
    "svc_average = np.mean(svc_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert proba to labels names\n",
    "nn_predicted_labels = np.argmax(nn_average, axis=1)\n",
    "svc_predicted_labels = np.argmax(svc_average, axis=1)\n",
    "class_names = svc_classifier.classes_\n",
    "nn_predicted_class_names = [class_names[label] for label in nn_predicted_labels]\n",
    "svc_predicted_class_names = [class_names[label] for label in svc_predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "true_labels = y_test\n",
    "svc_predicted_labels = svc_predicted_class_names\n",
    "nn_predicted_labels = nn_predicted_class_names\n",
    "class_names = svc_classifier.classes_\n",
    "\n",
    "# Calculate confusion matrix for each model\n",
    "svc_conf_matrix = confusion_matrix(true_labels, svc_predicted_labels)\n",
    "nn_conf_matrix = confusion_matrix(true_labels, nn_predicted_labels)\n",
    "\n",
    "# Calculate weighted F1 scores and accuracy for each model\n",
    "svc_weighted_f1_score = f1_score(true_labels, svc_predicted_labels, average='weighted')\n",
    "nn_weighted_f1_score = f1_score(true_labels, nn_predicted_labels, average='weighted')\n",
    "\n",
    "svc_accuracy = accuracy_score(true_labels, svc_predicted_labels)\n",
    "nn_accuracy = accuracy_score(true_labels, nn_predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix for each model\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# For SVC Model heatmap\n",
    "sns.heatmap(svc_conf_matrix, annot=True, fmt=\"d\", cmap=\"Greens\", ax=axes[0], xticklabels=class_names, yticklabels=class_names)\n",
    "axes[0].set_title(f\"SVC Model\\nWeighted F1 Score: {svc_weighted_f1_score:.2f}, Accuracy: {svc_accuracy:.2f}\")\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "\n",
    "# For NN Model heatmap\n",
    "sns.heatmap(nn_conf_matrix, annot=True, fmt=\"d\", cmap=\"Reds\", ax=axes[1], xticklabels=class_names, yticklabels=class_names)\n",
    "axes[1].set_title(f\"NN Model\\nWeighted F1 Score: {nn_weighted_f1_score:.2f}, Accuracy: {nn_accuracy:.2f}\")\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf7566",
   "metadata": {},
   "source": [
    "## reality simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the files for testing\n",
    "filename = 'length_reality_test_v1.pkl'\n",
    "file_path = 'C:\\\\python_intro\\\\final_project\\\\'\n",
    "with open(file_path + filename, 'rb') as file:\n",
    "    test_ratios = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the extra columns\n",
    "cols_to_normalize = test_ratios.columns[-3:]\n",
    "scaler = MinMaxScaler()\n",
    "# Normalize the last four columns\n",
    "test_ratios[cols_to_normalize] = scaler.fit_transform(test_ratios[cols_to_normalize])\n",
    "# Print the normalized DataFrame\n",
    "flatten_test = test_ratios.values\n",
    "graph_test = test_ratios.iloc[:, :50].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb35208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "NN_all = []\n",
    "svc_all = []\n",
    "for i in range(5):\n",
    "    #NN\n",
    "    # Define and compile neural network model\n",
    "    #define the model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "        #keras.layers.Dense(256, activation='relu'),\n",
    "        #keras.layers.Dense(256, activation='relu'),\n",
    "        #keras.layers.Dense(128, activation='relu'),\n",
    "        #keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "        #keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    # Add layers to the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train_NN, y_train_NN, validation_data=(X_test_NN, y_test_NN), epochs=100, callbacks=[early_stopping])\n",
    "    # Use the model obtained at the end of training\n",
    "    predictions = model.predict(flatten_test)\n",
    "    NN_all.append(predictions)\n",
    "    \n",
    "    #SVC\n",
    "    svc_classifier = SVC(C = 250, gamma = 1, kernel = 'rbf',probability=True, random_state=42)\n",
    "    svc_classifier.fit(X_train, y_train)\n",
    "    svc_pre = svc_classifier.predict_proba(flatten_test)\n",
    "    svc_all.append(svc_pre)\n",
    "    \n",
    "#get the average values of 5 times of training\n",
    "NN_average = np.mean(NN_all, axis=0)\n",
    "svc_average = np.mean(svc_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8aeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = svc_classifier.classes_\n",
    "all_probabilities = [\n",
    "    NN_average,\n",
    "    svc_average\n",
    "]\n",
    "\n",
    "results = []  # List to store the results\n",
    "\n",
    "for probabilities in all_probabilities:\n",
    "    # Get the top 3 labels with highest probabilities for each event\n",
    "    top3_labels = np.argsort(-probabilities, axis=1)[:, :3]  # Indices of top 3 labels for each event\n",
    "\n",
    "    # Retrieve the label names and corresponding probabilities\n",
    "    top3_labels_names = np.take(labels, top3_labels)  # Retrieve the label names based on indices\n",
    "    top3_probabilities = np.take_along_axis(probabilities, top3_labels, axis=1)  # Retrieve corresponding probabilities\n",
    "\n",
    "    # Create a DataFrame to store the results for the current set\n",
    "    set_results = pd.DataFrame({\n",
    "        'Event': np.arange(1, len(probabilities) + 1),  # Event numbers\n",
    "        'Label 1': top3_labels_names[:, 0],\n",
    "        'Label 2': top3_labels_names[:, 1],\n",
    "        'Label 3': top3_labels_names[:, 2],\n",
    "        'Probability 1': top3_probabilities[:, 0],\n",
    "        'Probability 2': top3_probabilities[:, 1],\n",
    "        'Probability 3': top3_probabilities[:, 2]\n",
    "    })\n",
    "\n",
    "    results.append(set_results)  # Add the results of the current set to the list\n",
    "\n",
    "# Concatenate all set results into a single DataFrame\n",
    "all_results = pd.concat(results)\n",
    "\n",
    "# Print the complete results\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fc7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the testing dataset\n",
    "# Load the .mat file\n",
    "mat_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\event_test_length.mat')\n",
    "peak_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\pkmax_test_length.mat')\n",
    "width_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\width_test_length.mat')\n",
    "area_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\area_test_length.mat')\n",
    "\n",
    "for i in range(len(mat_file[\"Event\"][0])):\n",
    "    # Access the data in the .mat file\n",
    "    env_time = ((mat_file[\"Event\"][0][i][0][0][2]).T)[0]\n",
    "    env_current = ((mat_file[\"Event\"][0][i][0][0][1]).T)[0]\n",
    "\n",
    "    # Create a plot\n",
    "    plt.scatter(env_time,env_current)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Current')\n",
    "    plt.title('Current vs Time')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    print(all_results.iloc[i+0], all_results.iloc[i+30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e9277",
   "metadata": {},
   "source": [
    "## CNN model training and CNN's reality simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the packages and install packages\n",
    "#pip install pyabf\n",
    "import pyabf\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bdcca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the files for training\n",
    "filename = 'combined_length_2000px_v1.pkl'\n",
    "file_path = 'C:\\\\python_intro\\\\final_project\\\\'\n",
    "with open(file_path + filename, 'rb') as file:\n",
    "    combined_ratios_all = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns except the last two as inputs\n",
    "combined_ratios = combined_ratios_all.iloc[:, :-3]\n",
    "# Select the last two columns as labels\n",
    "labels = combined_ratios_all.iloc[:, -2:]\n",
    "\n",
    "labels_column = labels[2005].tolist()\n",
    "#binary_labels = [0 if label == 0 else 1 for label in labels_column]\n",
    "ground_truth = labels_column\n",
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing all the columns\n",
    "cols_to_normalize = combined_ratios.columns[-3:]\n",
    "scaler = MinMaxScaler()\n",
    "# Normalize the last four columns\n",
    "combined_ratios[cols_to_normalize] = scaler.fit_transform(combined_ratios[cols_to_normalize])\n",
    "# Print the normalized DataFrame\n",
    "combined_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ground_truth to a numpy array for easier indexing\n",
    "from sklearn.model_selection import train_test_split\n",
    "ground_truth = np.array(ground_truth)\n",
    "# Initialize empty lists to store training and testing datasets and labels\n",
    "training_data = []\n",
    "testing_data = []\n",
    "training_labels = []\n",
    "testing_labels = []\n",
    "\n",
    "# Get unique labels from the ground_truth list\n",
    "unique_labels = np.unique(ground_truth)\n",
    "\n",
    "# Iterate over each unique label\n",
    "for label in unique_labels:\n",
    "    # Find the indices where the label matches\n",
    "    label_indices = np.where(ground_truth == label)[0]\n",
    "\n",
    "    # Check if there is more than one sample for the label\n",
    "    if len(label_indices) > 1:\n",
    "        # Split the label indices into training and testing sets with an 80/20 ratio\n",
    "        train_indices, test_indices = train_test_split(label_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Append the corresponding rows from combined_ratios to the training and testing datasets\n",
    "        training_data.append(combined_ratios.iloc[train_indices])\n",
    "        testing_data.append(combined_ratios.iloc[test_indices])\n",
    "\n",
    "        # Append the corresponding labels to the training and testing labels\n",
    "        training_labels.extend(ground_truth[train_indices])\n",
    "        testing_labels.extend(ground_truth[test_indices])\n",
    "\n",
    "# Concatenate all training datasets into a single DataFrame\n",
    "training_data = pd.concat(training_data)\n",
    "\n",
    "# Concatenate all testing datasets into a single DataFrame\n",
    "testing_data = pd.concat(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc823ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_flatten = training_data.values\n",
    "testing_flatten = testing_data.values\n",
    "training_graph_data = training_data.iloc[:, :2000].values\n",
    "testing_graph_data = testing_data.iloc[:, :2000].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert ground truth to encoded_labels for NN\n",
    "unique_training_classes = np.unique(training_labels)# Find the unique classes\n",
    "unique_testing_classes = np.unique(testing_labels)\n",
    "\n",
    "num_training_classes = len(unique_training_classes)\n",
    "num_testing_classes = len(unique_testing_classes)\n",
    "\n",
    "encoded_training_labels = np.zeros((len(training_labels), num_training_classes))  # Initialize an array for one-hot encoding\n",
    "encoded_testing_labels = np.zeros((len(testing_labels), num_testing_classes))\n",
    "\n",
    "for i, label in enumerate(training_labels):\n",
    "    class_training_index = np.where(unique_training_classes == label)[0][0]  # Find the index of the class\n",
    "    encoded_training_labels[i, class_training_index] = 1  # Set the corresponding element to 1\n",
    "    \n",
    "for i, label in enumerate(testing_labels):\n",
    "    class_testing_index = np.where(unique_testing_classes == label)[0][0]  # Find the index of the class\n",
    "    encoded_testing_labels[i, class_testing_index] = 1  # Set the corresponding element to 1\n",
    "\n",
    "print(encoded_testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8cac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and testing datasets for all descriptor datasets\n",
    "X_train_NN = np.array(training_graph_data)\n",
    "X_test_NN = np.array(testing_graph_data)\n",
    "y_train_NN = encoded_training_labels\n",
    "y_test_NN = encoded_testing_labels\n",
    "X_train = training_graph_data\n",
    "X_test = testing_graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d801196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert flatten current density information to CNN readable graphs\n",
    "# Original dimensions\n",
    "num_rows = 50\n",
    "num_columns = 40\n",
    "# Initialize an empty list to store the 2D arrays\n",
    "unflattened_training_arrays = []\n",
    "# Iterate over each row of the flattened array\n",
    "for row in X_train_NN:\n",
    "    # Reshape the row into a 2D array\n",
    "    unflattened_training_row = row.reshape(num_rows, num_columns)\n",
    "    # Append the unflattened row to the list\n",
    "    unflattened_training_arrays.append(unflattened_training_row)\n",
    "# Convert the list of 2D arrays into a new array\n",
    "training_graph_array = np.array(unflattened_training_arrays)\n",
    "\n",
    "unflattened_testing_arrays = []\n",
    "for row in X_test_NN:\n",
    "    # Reshape the row into a 2D array\n",
    "    unflattened_testing_row = row.reshape(num_rows, num_columns)\n",
    "    # Append the unflattened row to the list\n",
    "    unflattened_testing_arrays.append(unflattened_testing_row)\n",
    "# Convert the list of 2D arrays into a new array\n",
    "testing_graph_array = np.array(unflattened_testing_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test which CNN to use is better\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#get the datasets ready\n",
    "train_data = training_graph_array\n",
    "test_data = testing_graph_array\n",
    "train_labels = encoded_training_labels\n",
    "test_labels = encoded_testing_labels\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data.reshape(train_data.shape[0], -1))  # Fit the scaler on the flattened data\n",
    "\n",
    "train_data_normalized = scaler.transform(train_data.reshape(train_data.shape[0], -1))\n",
    "test_data_normalized = scaler.transform(test_data.reshape(test_data.shape[0], -1))\n",
    "\n",
    "# Reshape the normalized data back to 3D\n",
    "train_data_normalized_3d = train_data_normalized.reshape(train_data.shape)\n",
    "test_data_normalized_3d = test_data_normalized.reshape(test_data.shape)\n",
    "\n",
    "# Add a channel dimension to the data\n",
    "train_data_normalized_3d = np.expand_dims(train_data_normalized_3d, axis=-1)\n",
    "test_data_normalized_3d = np.expand_dims(test_data_normalized_3d, axis=-1)\n",
    "\n",
    "# Design CNN architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(64, kernel_size=(2, 2), activation=\"relu\", input_shape=train_data_normalized_3d.shape[1:]),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(128, kernel_size=(2, 2), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(256, kernel_size=(2, 2), activation=\"relu\", padding=\"same\"),\n",
    "    #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    #layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    #layers.Dense(128, activation='relu'),\n",
    "    #layers.Dense(128, activation='relu'),\n",
    "    #layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "num_runs = 10\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(train_data_normalized_3d, train_labels, epochs=100, batch_size=32, validation_data=(test_data_normalized_3d, test_labels), callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the best model on the test data\n",
    "    loss, accuracy = model.evaluate(test_data_normalized_3d, test_labels)\n",
    "    losses.append(loss)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the average loss and accuracy\n",
    "average_loss = sum(losses) / num_runs\n",
    "average_accuracy = sum(accuracies) / num_runs\n",
    "\n",
    "# Print the average loss and accuracy\n",
    "print(\"Average loss:\", average_loss)\n",
    "print(\"Average accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting CNN model's output\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#get the datasets ready\n",
    "train_data = training_graph_array\n",
    "test_data = testing_graph_array\n",
    "train_labels = encoded_training_labels\n",
    "test_labels = encoded_testing_labels\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data.reshape(train_data.shape[0], -1))  # Fit the scaler on the flattened data\n",
    "\n",
    "train_data_normalized = scaler.transform(train_data.reshape(train_data.shape[0], -1))\n",
    "test_data_normalized = scaler.transform(test_data.reshape(test_data.shape[0], -1))\n",
    "\n",
    "# Reshape the normalized data back to 3D\n",
    "train_data_normalized_3d = train_data_normalized.reshape(train_data.shape)\n",
    "test_data_normalized_3d = test_data_normalized.reshape(test_data.shape)\n",
    "\n",
    "# Add a channel dimension to the data\n",
    "train_data_normalized_3d = np.expand_dims(train_data_normalized_3d, axis=-1)\n",
    "test_data_normalized_3d = np.expand_dims(test_data_normalized_3d, axis=-1)\n",
    "\n",
    "# Design CNN architecture\n",
    "CNN_model = keras.Sequential([\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", input_shape=train_data_normalized_3d.shape[1:]),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(256, kernel_size=(2, 2), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten()\n",
    "])\n",
    "\n",
    "cnn_training_features = CNN_model(train_data_normalized_3d)\n",
    "cnn_testing_features = CNN_model(test_data_normalized_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a302a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the additional columns out and combine them with CNN data\n",
    "#define the additional data\n",
    "training_add = training_data.iloc[:,-3:]\n",
    "testing_add = testing_data.iloc[:,-3:]\n",
    "train_labels_add = encoded_training_labels\n",
    "test_labels_add = encoded_testing_labels\n",
    "\n",
    "# Reset the index of the additional data\n",
    "training_add.reset_index(drop=True, inplace=True)\n",
    "testing_add.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert the existing data to a DataFrame\n",
    "CNN_training_df = pd.DataFrame(cnn_training_features)\n",
    "CNN_testing_df = pd.DataFrame(cnn_testing_features)\n",
    "\n",
    "# Merge the existing data and additional data based on their indexes\n",
    "combined_training_data = pd.merge(CNN_training_df, training_add, left_index=True, right_index=True)\n",
    "combined_testing_data = pd.merge(CNN_testing_df, testing_add, left_index=True, right_index=True)\n",
    "combined_testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the NN model using the \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = keras.Sequential([\n",
    "    #keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    #keras.layers.Dense(64, activation='relu'),\n",
    "    #keras.layers.Dense(128, activation='relu'),\n",
    "    #keras.layers.Dense(128, activation='relu'),\n",
    "    #keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "num_runs = 10\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(combined_training_data, train_labels_add, epochs=100, batch_size=32, validation_data=(combined_testing_data, test_labels_add), callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the best model on the test data\n",
    "    loss, accuracy = model.evaluate(combined_testing_data, test_labels_add)\n",
    "    losses.append(loss)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the average loss and accuracy\n",
    "average_loss = sum(losses) / num_runs\n",
    "average_accuracy = sum(accuracies) / num_runs\n",
    "\n",
    "# Print the average loss and accuracy\n",
    "print(\"Average loss:\", average_loss)\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred_prob = model.predict(combined_testing_data)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "test_labels = np.argmax(test_labels_add, axis=1)\n",
    "\n",
    "#Calcualte f1 score\n",
    "f1 = f1_score(test_labels, y_pred, average='weighted')\n",
    "\n",
    "# Print the best epoch and F1 score\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "import winsound\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Code execution completed, play a beep sound\n",
    "frequency = 2500  # Set frequency (in Hz)\n",
    "duration = 1000   # Set duration (in milliseconds)\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce0381",
   "metadata": {},
   "source": [
    "## error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "true_labels = test_labels\n",
    "cnn_predicted_labels = y_pred\n",
    "\n",
    "class_names = [\"0\", \"10\", \"110\", \"1110\", \"10010\", \"10100\", \"10110\", \"110010\", \"110100\", \"110110\"]\n",
    "\n",
    "# Calculate the confusion matrix for the CNN model\n",
    "cnn_conf_matrix = confusion_matrix(true_labels, cnn_predicted_labels)\n",
    "\n",
    "# Calculate the weighted F1 score and accuracy for the CNN model\n",
    "cnn_weighted_f1_score = f1_score(true_labels, cnn_predicted_labels, average='weighted')\n",
    "cnn_accuracy = accuracy_score(true_labels, cnn_predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cnn_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f\"CNN Model\\nWeighted F1 Score: {cnn_weighted_f1_score:.2f}, Accuracy: {cnn_accuracy:.2f}\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca92c1",
   "metadata": {},
   "source": [
    "## CNN reality simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the files for testing\n",
    "filename = 'cnn_length_test_v1.pkl'\n",
    "file_path = 'C:\\\\python_intro\\\\final_project\\\\'\n",
    "with open(file_path + filename, 'rb') as file:\n",
    "    test_ratios = pickle.load(file)\n",
    "#if the combined ratios is saving as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the extra columns\n",
    "cols_to_normalize = test_ratios.columns[-3:]\n",
    "scaler = MinMaxScaler()\n",
    "# Normalize the last four columns\n",
    "test_ratios[cols_to_normalize] = scaler.fit_transform(test_ratios[cols_to_normalize])\n",
    "# Print the normalized DataFrame\n",
    "flatten_test = test_ratios.values\n",
    "graph_test = test_ratios.iloc[:, :2000].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62437db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert testing dataset to CNN readable graphs\n",
    "# Original dimensions\n",
    "num_rows = 50\n",
    "num_columns = 40\n",
    "# Initialize an empty list to store the 2D arrays\n",
    "unflattened_testing_arrays = []\n",
    "# Iterate over each row of the flattened array\n",
    "for row in graph_test:\n",
    "    # Reshape the row into a 2D array\n",
    "    unflattened_testing_row = row.reshape(num_rows, num_columns)\n",
    "    # Append the unflattened row to the list\n",
    "    unflattened_testing_arrays.append(unflattened_testing_row)\n",
    "# Convert the list of 2D arrays into a new array\n",
    "test_graph_array = np.array(unflattened_testing_arrays)\n",
    "len(test_graph_array[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the dataset after CNN processing\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(test_graph_array.reshape(test_graph_array.shape[0], -1))  # Fit the scaler on the flattened data\n",
    "\n",
    "reality_data_normalized = scaler.transform(test_graph_array.reshape(test_graph_array.shape[0], -1))\n",
    "\n",
    "# Reshape the normalized data back to 3D\n",
    "reality_data_normalized_3d = reality_data_normalized.reshape(test_graph_array.shape)\n",
    "\n",
    "# Add a channel dimension to the data\n",
    "reality_data_normalized_3d = np.expand_dims(reality_data_normalized_3d, axis=-1)\n",
    "\n",
    "#use the predefined CNN model to extract CNN features\n",
    "cnn_reality_features = CNN_model(reality_data_normalized_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the additional columns out and combine them with CNN data\n",
    "additional_reality_data = test_ratios.iloc[:,-3:]\n",
    "\n",
    "# Reset the index of the additional data\n",
    "additional_reality_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert the existing data to a DataFrame\n",
    "cnn_reality_features_df = pd.DataFrame(cnn_reality_features)\n",
    "\n",
    "# Merge the existing data and additional data based on their indexes\n",
    "combined_reality_data = pd.merge(cnn_reality_features_df, additional_reality_data, left_index=True, right_index=True)\n",
    "combined_reality_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dfb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the NN for 5 times and get the average results\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "CNN_all = []\n",
    "for i in range(5):\n",
    "    # Define and compile neural network model\n",
    "    #define the model\n",
    "    model = keras.Sequential([\n",
    "        #keras.layers.Flatten(),\n",
    "        #keras.layers.Dense(256, activation='relu'),\n",
    "        #keras.layers.Dense(256, activation='relu'),\n",
    "        #keras.layers.Dense(128, activation='relu'),\n",
    "        #keras.layers.Dense(128, activation='relu'),\n",
    "        #keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "        #keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    # Add layers to the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(combined_training_data, train_labels_add, epochs=100, batch_size=32, validation_data=(combined_testing_data, test_labels_add), callbacks=[early_stopping])\n",
    "    # Use the model obtained at the end of training\n",
    "    predictions = model.predict(combined_reality_data)\n",
    "    CNN_all.append(predictions)\n",
    "#get the average values of 5 times of training\n",
    "CNN_average = np.mean(CNN_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ab960",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([0,10,110,1110,10010,10100,10110,110010,110100,110110])\n",
    "all_probabilities = [\n",
    "    CNN_average\n",
    "]\n",
    "\n",
    "results = []  # List to store the results\n",
    "\n",
    "for probabilities in all_probabilities:\n",
    "    # Get the top 3 labels with highest probabilities for each event\n",
    "    top3_labels = np.argsort(-probabilities, axis=1)[:, :3]  # Indices of top 3 labels for each event\n",
    "\n",
    "    # Retrieve the label names and corresponding probabilities\n",
    "    top3_labels_names = np.take(labels, top3_labels)  # Retrieve the label names based on indices\n",
    "    top3_probabilities = np.take_along_axis(probabilities, top3_labels, axis=1)  # Retrieve corresponding probabilities\n",
    "\n",
    "    # Create a DataFrame to store the results for the current set\n",
    "    set_results = pd.DataFrame({\n",
    "        'Event': np.arange(1, len(probabilities) + 1),  # Event numbers\n",
    "        'Label 1': top3_labels_names[:, 0],\n",
    "        'Label 2': top3_labels_names[:, 1],\n",
    "        'Label 3': top3_labels_names[:, 2],\n",
    "        'Probability 1': top3_probabilities[:, 0],\n",
    "        'Probability 2': top3_probabilities[:, 1],\n",
    "        'Probability 3': top3_probabilities[:, 2]\n",
    "    })\n",
    "\n",
    "    results.append(set_results)  # Add the results of the current set to the list\n",
    "\n",
    "# Concatenate all set results into a single DataFrame\n",
    "all_results = pd.concat(results)\n",
    "\n",
    "# Print the complete results\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85277eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the testing dataset\n",
    "# Load the .mat file\n",
    "mat_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\event_test_length.mat')\n",
    "peak_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\pkmax_test_length.mat')\n",
    "width_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\width_test_length.mat')\n",
    "area_file = scipy.io.loadmat('C:\\\\python_intro\\\\final_project\\\\matfiles\\\\test_files\\\\area_test_length.mat')\n",
    "\n",
    "for i in range(len(mat_file[\"Event\"][0])):\n",
    "    # Access the data in the .mat file\n",
    "    env_time = ((mat_file[\"Event\"][0][i][0][0][2]).T)[0]\n",
    "    env_current = ((mat_file[\"Event\"][0][i][0][0][1]).T)[0]\n",
    "\n",
    "    # Create a plot\n",
    "    plt.scatter(env_time,env_current)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Current')\n",
    "    plt.title('Current vs Time')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    print(all_results.iloc[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
